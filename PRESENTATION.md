# ğŸ“Š Data Pipeline Streaming - PrÃ©sentation du Projet

## ğŸ¯ Qu'est-ce que c'est ?

**Data Pipeline Streaming** est un **pipeline de donnÃ©es de bout-en-bout** (end-to-end data pipeline) qui illustre le processus complet de traitement de donnÃ©es financiÃ¨res, de la **gÃ©nÃ©ration** Ã  la **visualisation**. 

Ce projet simule un systÃ¨me de traitement de transactions en temps rÃ©el avec des donnÃ©es synthÃ©tiques, dÃ©montrant les concepts essentiels du traitement de donnÃ©es modernes.

---

## ğŸš€ Ã€ quoi Ã§a sert ?

### 1. **GÃ©nÃ©ration de DonnÃ©es** ğŸ“
- âœ… GÃ©nÃ¨re des **transactions financiÃ¨res synthÃ©tiques** rÃ©alistes
- âœ… Simule un flux de donnÃ©es en temps rÃ©el
- âœ… Montants, catÃ©gories, marchands, villes, statuts variÃ©s
- âœ… Permet de tester et dÃ©montrer des pipelines sans donnÃ©es rÃ©elles

### 2. **Ingestion de DonnÃ©es** ğŸ”„
- âœ… Collecte les transactions depuis diffÃ©rentes sources
- âœ… Support de **Kafka** (messagerie distribuÃ©e) ou **fichiers JSONL**
- âœ… GÃ¨re le flux de donnÃ©es de maniÃ¨re fiable et scalable
- âœ… Support de diffÃ©rents formats de donnÃ©es

### 3. **Transformation de DonnÃ©es (ETL)** ğŸ”§
- âœ… Transforme les donnÃ©es brutes en donnÃ©es structurÃ©es
- âœ… Applique des **rÃ¨gles de qualitÃ© de donnÃ©es**
- âœ… Enrichit les donnÃ©es avec des mÃ©tadonnÃ©es (dates, heures, buckets de montants)
- âœ… Nettoie et valide les donnÃ©es
- âœ… Support de **Apache Airflow** pour l'orchestration

### 4. **Stockage de DonnÃ©es** ğŸ’¾
- âœ… Stocke les donnÃ©es dans une base de donnÃ©es
- âœ… Support de **SQLite** (version simplifiÃ©e) et **PostgreSQL** (version complÃ¨te)
- âœ… Maintient une version brute et une version transformÃ©e
- âœ… CrÃ©e des index pour des requÃªtes rapides
- âœ… Support de vues matÃ©rialisÃ©es pour des agrÃ©gations

### 5. **Visualisation et Analyse** ğŸ“ˆ
- âœ… **Dashboard interactif** avec Streamlit
- âœ… Graphiques et mÃ©triques en temps rÃ©el
- âœ… **Filtres avancÃ©s** (catÃ©gorie, ville, statut, montant, date)
- âœ… Export des donnÃ©es pour analyse externe (CSV)
- âœ… Analyses statistiques (montants, tendances, top marchands)

### 6. **Cas d'Usage RÃ©els** ğŸ¯

#### Pour les Ã‰tudiants
- ğŸ“š Apprendre les concepts de traitement de donnÃ©es
- ğŸ“š Comprendre les pipelines de donnÃ©es
- ğŸ“š Pratiquer avec les technologies modernes

#### Pour les DÃ©veloppeurs
- ğŸ’¼ DÃ©monstration de compÃ©tences techniques
- ğŸ’¼ Prototypage rapide de solutions
- ğŸ’¼ Base pour des projets plus complexes

#### Pour les Data Engineers
- ğŸ”§ Exemple de pipeline de donnÃ©es complet
- ğŸ”§ RÃ©fÃ©rence pour des projets similaires
- ğŸ”§ DÃ©monstration de best practices

#### Pour les Analystes de DonnÃ©es
- ğŸ“Š Analyse de donnÃ©es financiÃ¨res
- ğŸ“Š Visualisation interactive
- ğŸ“Š Export de donnÃ©es pour PowerBI, Tableau, etc.

---

## ğŸ› ï¸ Technologies UtilisÃ©es

### **ğŸ”· Backend & DonnÃ©es**

#### 1. **Python 3.11+** ğŸ
- Langage de programmation principal
- UtilisÃ© pour tous les scripts de traitement de donnÃ©es
- BibliothÃ¨ques : Pandas, SQLAlchemy, Kafka-Python

#### 2. **Apache Kafka** (Optionnel) ğŸ“¨
- SystÃ¨me de messagerie distribuÃ©e
- GÃ¨re le flux de donnÃ©es en temps rÃ©el
- Permet la communication asynchrone entre services
- UtilisÃ© pour l'ingestion de donnÃ©es en streaming

#### 3. **Zookeeper** (Optionnel) ğŸ˜
- Service de coordination pour Kafka
- GÃ¨re la configuration et la synchronisation
- UtilisÃ© avec Kafka pour la gestion des clusters

#### 4. **SQLite** (Version SimplifiÃ©e) ğŸ—„ï¸
- Base de donnÃ©es lÃ©gÃ¨re et embarquÃ©e
- Stocke les transactions et les mÃ©tadonnÃ©es
- Pas besoin de serveur sÃ©parÃ©
- IdÃ©al pour le dÃ©veloppement et les dÃ©monstrations

#### 5. **PostgreSQL** (Version ComplÃ¨te) ğŸ˜
- Base de donnÃ©es relationnelle robuste
- Stocke les donnÃ©es brutes et transformÃ©es
- Supporte des requÃªtes complexes
- UtilisÃ© dans la version Docker complÃ¨te

#### 6. **Apache Airflow** (Optionnel) ğŸŒŠ
- Orchestrateur de workflows
- GÃ¨re l'exÃ©cution des tÃ¢ches ETL
- Planifie et surveille les pipelines
- Interface web pour la gestion des DAGs (Directed Acyclic Graphs)

### **ğŸ”· Frontend & Visualisation**

#### 7. **Streamlit** ğŸ¨
- Framework Python pour crÃ©er des applications web
- Dashboard interactif et responsive
- Graphiques et visualisations intÃ©grÃ©s
- Filtres et contrÃ´les utilisateur
- DÃ©ploiement facile sur Streamlit Cloud

#### 8. **Pandas** ğŸ“Š
- BibliothÃ¨que Python pour l'analyse de donnÃ©es
- Manipulation et transformation de donnÃ©es
- AgrÃ©gations et calculs statistiques
- Export de donnÃ©es (CSV, JSON, etc.)

#### 9. **Altair** (via Streamlit) ğŸ“ˆ
- BibliothÃ¨que de visualisation de donnÃ©es
- Graphiques interactifs
- IntÃ©gration native avec Streamlit
- Support de diffÃ©rents types de graphiques (barres, lignes, etc.)

### **ğŸ”· Infrastructure & DÃ©ploiement**

#### 10. **Docker & Docker Compose** (Optionnel) ğŸ³
- Conteneurisation des services
- Orchestration de plusieurs services (Kafka, Zookeeper, Postgres, Airflow)
- Facilite le dÃ©ploiement et la mise Ã  l'Ã©chelle
- Environnement de dÃ©veloppement reproductible

#### 11. **Git & GitHub** ğŸ“¦
- ContrÃ´le de version
- Collaboration et partage de code
- Historique des modifications
- IntÃ©gration avec Streamlit Cloud

#### 12. **Streamlit Cloud** â˜ï¸
- Plateforme de dÃ©ploiement pour Streamlit
- DÃ©ploiement automatique depuis GitHub
- Hosting gratuit
- Mise Ã  jour automatique

### **ğŸ”· Outils & BibliothÃ¨ques**

#### 13. **SQLAlchemy** ğŸ”—
- ORM (Object-Relational Mapping) pour Python
- Abstraction de la base de donnÃ©es
- Support de SQLite et PostgreSQL
- RequÃªtes SQL simplifiÃ©es

#### 14. **Kafka-Python** ğŸ“¨
- Client Kafka pour Python
- Production et consommation de messages
- Gestion des topics et partitions
- Support des consumers et producers

#### 15. **Click** ğŸ–±ï¸
- Framework CLI pour Python
- CrÃ©ation de commandes en ligne de commande
- Arguments et options personnalisables
- Interface utilisateur intuitive

#### 16. **TQDM** ğŸ“Š
- Barre de progression pour Python
- Affichage du progrÃ¨s des tÃ¢ches
- Estimation du temps restant
- AmÃ©lioration de l'expÃ©rience utilisateur

#### 17. **Python-dotenv** ğŸ”
- Gestion des variables d'environnement
- Configuration sÃ©curisÃ©e
- Support des fichiers .env
- SÃ©paration des configurations

---

## ğŸ“Š Architecture du Projet

### **Version SimplifiÃ©e (Sans Docker) - RECOMMANDÃ‰**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Producer          â”‚ â†’ GÃ©nÃ¨re des transactions synthÃ©tiques
â”‚   (Python)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Fichier JSONL     â”‚ â†’ Stockage temporaire des transactions
â”‚   (data/queue/)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ETL Script        â”‚ â†’ Transformation des donnÃ©es
â”‚   (Python)          â”‚   - Validation
â”‚                     â”‚   - Enrichissement
â”‚                     â”‚   - Nettoyage
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SQLite DB         â”‚ â†’ Stockage des donnÃ©es
â”‚   (data/)           â”‚   - raw_transactions
â”‚                     â”‚   - transactions_flat
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit         â”‚ â†’ Visualisation et analyse
â”‚   Dashboard         â”‚   - Graphiques
â”‚                     â”‚   - Filtres
â”‚                     â”‚   - Export CSV
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Version ComplÃ¨te (Avec Docker)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Producer          â”‚ â†’ GÃ©nÃ¨re des transactions synthÃ©tiques
â”‚   (Python)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka             â”‚ â†’ Messagerie distribuÃ©e
â”‚   + Zookeeper       â”‚   - Topics
â”‚   (Docker)          â”‚   - Partitions
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Airflow           â”‚ â†’ Orchestration ETL
â”‚   (DAGs)            â”‚   - Planification
â”‚   (Docker)          â”‚   - Surveillance
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL        â”‚ â†’ Base de donnÃ©es
â”‚   (Docker)          â”‚   - raw_transactions
â”‚                     â”‚   - transactions_flat
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit         â”‚ â†’ Visualisation et analyse
â”‚   Dashboard         â”‚   - Graphiques
â”‚                     â”‚   - Filtres
â”‚                     â”‚   - Export CSV
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ CompÃ©tences DÃ©veloppÃ©es

### **Techniques** ğŸ”§
- âœ… **Traitement de donnÃ©es** : ETL, transformation, nettoyage
- âœ… **Bases de donnÃ©es** : SQL, SQLite, PostgreSQL
- âœ… **Streaming de donnÃ©es** : Kafka, messages en temps rÃ©el
- âœ… **Orchestration** : Airflow, DAGs, workflows
- âœ… **Visualisation** : Streamlit, graphiques, dashboards
- âœ… **DÃ©ploiement** : Docker, Streamlit Cloud, GitHub

### **Concepts** ğŸ’¡
- âœ… **Pipeline de donnÃ©es** : Flux de donnÃ©es de bout-en-bout
- âœ… **Temps rÃ©el** : Traitement en streaming
- âœ… **Micro-batch** : Traitement par lots
- âœ… **Data Quality** : Validation et nettoyage des donnÃ©es
- âœ… **Data Warehousing** : Stockage et organisation des donnÃ©es
- âœ… **Business Intelligence** : Analyse et visualisation

---

## ğŸ“ˆ FonctionnalitÃ©s Principales

### **1. GÃ©nÃ©ration de DonnÃ©es** ğŸ“
- âœ… Transactions synthÃ©tiques rÃ©alistes
- âœ… Multiples catÃ©gories (grocery, electronics, travel, etc.)
- âœ… DiffÃ©rents marchands (Amazon, Uber, Carrefour, etc.)
- âœ… DiffÃ©rentes villes (Paris, Lyon, Marseille, etc.)
- âœ… Statuts variÃ©s (APPROVED, DECLINED, PENDING, REFUNDED)
- âœ… Montants variables (5â‚¬ Ã  750â‚¬)
- âœ… Timestamps rÃ©alistes

### **2. Transformation de DonnÃ©es** ğŸ”§
- âœ… Validation des donnÃ©es
- âœ… Enrichissement des donnÃ©es
- âœ… Calcul de mÃ©triques (buckets de montants, heures, jours)
- âœ… Extraction de mÃ©tadonnÃ©es
- âœ… Nettoyage et normalisation

### **3. Visualisation** ğŸ“Š
- âœ… Dashboard interactif
- âœ… Graphiques en temps rÃ©el
- âœ… Filtres avancÃ©s (catÃ©gorie, ville, statut, montant, date)
- âœ… MÃ©triques clÃ©s (total, moyenne, approuvÃ©es)
- âœ… Export de donnÃ©es (CSV)

### **4. Analyse** ğŸ“ˆ
- âœ… Analyse par catÃ©gorie
- âœ… Analyse par ville
- âœ… Analyse par marchand
- âœ… Analyse par statut
- âœ… Analyse par pÃ©riode
- âœ… Top 10 marchands
- âœ… Tendances temporelles

---

## ğŸŒŸ Points Forts du Projet

### **1. FlexibilitÃ©** ğŸ”„
- âœ… Version simplifiÃ©e (sans Docker) - **RECOMMANDÃ‰**
- âœ… Version complÃ¨te (avec Docker)
- âœ… DÃ©ploiement local ou cloud
- âœ… Support de multiples bases de donnÃ©es (SQLite, PostgreSQL)

### **2. FacilitÃ© d'Utilisation** ğŸ¯
- âœ… Interface utilisateur intuitive
- âœ… Scripts en ligne de commande
- âœ… Documentation complÃ¨te
- âœ… Exemples et guides

### **3. ScalabilitÃ©** ğŸ“ˆ
- âœ… Support de grandes quantitÃ©s de donnÃ©es
- âœ… Traitement par lots
- âœ… Optimisation des requÃªtes
- âœ… Index sur les colonnes importantes

### **4. ExtensibilitÃ©** ğŸ”§
- âœ… Architecture modulaire
- âœ… Facile Ã  Ã©tendre
- âœ… Support de nouvelles fonctionnalitÃ©s
- âœ… IntÃ©gration avec d'autres outils

---

## ğŸš€ DÃ©marrage Rapide

### **Version SimplifiÃ©e (Sans Docker) - RECOMMANDÃ‰**

```powershell
# 1. Installer les dÃ©pendances
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements-simple.txt

# 2. CrÃ©er la base de donnÃ©es et gÃ©nÃ©rer des donnÃ©es
python create_database.py

# 3. Lancer le dashboard
streamlit run streamlit_app.py
```

### **Version ComplÃ¨te (Avec Docker)**

```bash
# 1. DÃ©marrer l'Ã©cosystÃ¨me
docker compose up -d

# 2. Activer le DAG dans Airflow UI (http://localhost:8080)

# 3. Produire des Ã©vÃ©nements
python producer/producer.py --rows 10000 --rate 100

# 4. Visualiser
streamlit run analytics/streamlit_dashboard.py
```

---

## ğŸ“š Ressources

### **Documentation** ğŸ“–
- [README.md](README.md) - Documentation principale
- [GUIDE-ANALYSE-NOUVELLE-BD.md](GUIDE-ANALYSE-NOUVELLE-BD.md) - Guide d'analyse
- [QUICKSTART.md](QUICKSTART.md) - DÃ©marrage rapide
- [DEPLOY.md](DEPLOY.md) - Guide de dÃ©ploiement
- [AMELIORATIONS-PROJET.md](AMELIORATIONS-PROJET.md) - AmÃ©liorations

### **Code Source** ğŸ’»
- **GitHub Repository**: https://github.com/Nedim7050/data-pipeline-streaming
- **Streamlit Cloud**: https://streamlit.io/cloud

### **Technologies** ğŸ› ï¸
- [Python](https://www.python.org/) - Langage de programmation
- [Streamlit](https://streamlit.io/) - Framework de visualisation
- [Kafka](https://kafka.apache.org/) - Messagerie distribuÃ©e
- [Airflow](https://airflow.apache.org/) - Orchestration
- [PostgreSQL](https://www.postgresql.org/) - Base de donnÃ©es
- [SQLite](https://www.sqlite.org/) - Base de donnÃ©es lÃ©gÃ¨re

---

## ğŸ‰ Conclusion

**Data Pipeline Streaming** est un projet complet qui dÃ©montre les concepts essentiels du traitement de donnÃ©es modernes. Il combine des technologies puissantes pour crÃ©er un pipeline de donnÃ©es fonctionnel, de la gÃ©nÃ©ration Ã  la visualisation.

### **Pourquoi ce projet ?**
- âœ… **Apprendre** : Comprendre les pipelines de donnÃ©es
- âœ… **DÃ©montrer** : Montrer des compÃ©tences techniques
- âœ… **Prototyper** : Tester rapidement des idÃ©es
- âœ… **Analyser** : Analyser des donnÃ©es financiÃ¨res

### **Qui peut l'utiliser ?**
- ğŸ“š **Ã‰tudiants** : Apprentissage des concepts
- ğŸ’¼ **DÃ©veloppeurs** : DÃ©monstration de compÃ©tences
- ğŸ”§ **Data Engineers** : Exemple de pipeline
- ğŸ“Š **Analystes** : Analyse de donnÃ©es

---

**ğŸš€ PrÃªt Ã  commencer ?** Consultez le [README.md](README.md) pour les instructions de dÃ©marrage !

**ğŸ“Š Voir le projet en action :** DÃ©ployez sur [Streamlit Cloud](https://streamlit.io/cloud) pour une dÃ©monstration live !

---

*DerniÃ¨re mise Ã  jour : DÃ©cembre 2024*
